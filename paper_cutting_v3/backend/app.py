#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯•å·è¯†åˆ« Demo - åç«¯æœåŠ¡
æ•´åˆé˜¿é‡Œäº‘è¯»å…‰ OCR å’Œ GLM ä¼˜åŒ–
"""

import re
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import os
import json
import base64
import io
from pathlib import Path
try:
    from PIL import Image
except ImportError:
    pass


# å¯¼å…¥æœ¬åœ°æ¨¡å—
from aliyun_paper import AliyunPaperOCR
from glm_optimizer import GLMOptimizer
from dotenv import load_dotenv

# é…ç½®è·¯å¾„
BASE_DIR = Path(__file__).parent.parent
load_dotenv(BASE_DIR / '.env')

FRONTEND_DIR = BASE_DIR / 'frontend'
STATIC_DIR = FRONTEND_DIR / 'static'
UPLOAD_FOLDER = BASE_DIR / 'uploads'
OUTPUT_FOLDER = BASE_DIR / 'output'

app = Flask(__name__, 
            static_folder=str(STATIC_DIR),
            static_url_path='/static')
CORS(app)

# ç¡®ä¿ç›®å½•å­˜åœ¨
UPLOAD_FOLDER.mkdir(exist_ok=True)
OUTPUT_FOLDER.mkdir(exist_ok=True)

# åˆå§‹åŒ–å¤„ç†å™¨
aliyun_ocr = None
glm_optimizer = None

def init_processors():
    """åˆå§‹åŒ– OCR å¤„ç†å™¨"""
    global aliyun_ocr, glm_optimizer
    
    # é˜¿é‡Œäº‘ OCR
    aliyun_key_id = os.getenv('ALIYUN_ACCESS_KEY_ID')
    aliyun_key_secret = os.getenv('ALIYUN_ACCESS_KEY_SECRET')
    
    if aliyun_key_id and aliyun_key_secret:
        aliyun_ocr = AliyunPaperOCR(aliyun_key_id, aliyun_key_secret)
        print("âœ“ é˜¿é‡Œäº‘ OCR åˆå§‹åŒ–æˆåŠŸ")
    else:
        print("âš ï¸  é˜¿é‡Œäº‘å¯†é’¥æœªè®¾ç½®")
    
    # GLM ä¼˜åŒ–å™¨
    glm_api_key = os.getenv('GLM_API_KEY')
    if glm_api_key:
        glm_optimizer = GLMOptimizer(api_key=glm_api_key)
        print("âœ“ GLM ä¼˜åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
    else:
        print("âš ï¸  GLM API Key æœªè®¾ç½®")


@app.route('/')
def index():
    """è¿”å›å‰ç«¯é¡µé¢"""
    return send_from_directory(FRONTEND_DIR, 'index.html')


@app.route('/api/upload', methods=['POST'])
def upload_image():
    """ä¸Šä¼ å›¾ç‰‡å¹¶è°ƒç”¨é˜¿é‡Œäº‘è¯†åˆ«"""
    if not aliyun_ocr:
        return jsonify({
            'status': 'error',
            'message': 'é˜¿é‡Œäº‘ OCR æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡'
        }), 500
    
    if 'file' not in request.files:
        return jsonify({
            'status': 'error',
            'message': 'æœªæ‰¾åˆ°æ–‡ä»¶'
        }), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({
            'status': 'error',
            'message': 'æ–‡ä»¶åä¸ºç©º'
        }), 400
    
    try:
        # ä½¿ç”¨åŸå§‹æ–‡ä»¶å(å»æ‰æ‰©å±•å)ä½œä¸ºç›®å½•å
        original_filename = Path(file.filename).stem
        
        # ä¸ºè¿™ä¸ªå›¾ç‰‡åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
        image_output_dir = OUTPUT_FOLDER / original_filename
        image_output_dir.mkdir(exist_ok=True, parents=True)
        
        # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡åˆ°è¾“å‡ºç›®å½•
        filepath = image_output_dir / file.filename
        file.save(filepath)
        
        print(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜: {filepath}")
        
        # åˆ›å»ºåˆ‡å›¾å­ç›®å½•
        images_dir = image_output_dir / 'images'
        images_dir.mkdir(exist_ok=True)
        
        # è°ƒç”¨é˜¿é‡Œäº‘ OCR
        print("ğŸ” å¼€å§‹é˜¿é‡Œäº‘è¯†åˆ«...")
        ocr_result = aliyun_ocr.recognize_paper(
            image_path=str(filepath),
            extract_images=False  # å…ˆä¸åˆ‡å›¾,åé¢æ‰‹åŠ¨å¤„ç†
        )
        
        # è§£æ Data å­—æ®µ(å¦‚æœæ˜¯å­—ç¬¦ä¸²)
        if 'Data' in ocr_result and isinstance(ocr_result['Data'], str):
            import json as json_lib
            ocr_result['Data'] = json_lib.loads(ocr_result['Data'])
        
        # ä¿å­˜é˜¿é‡Œäº‘åŸå§‹ JSON åˆ°å›¾ç‰‡ç›®å½•(å®Œæ•´æ ¼å¼åŒ–)
        aly_json_path = image_output_dir / f"{original_filename}_aly.json"
        with open(aly_json_path, 'w', encoding='utf-8') as f:
            json.dump(ocr_result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ é˜¿é‡Œäº‘ç»“æœå·²ä¿å­˜: {aly_json_path}")
        
        # æ‰‹åŠ¨åˆ‡å›¾:åªåˆ‡ subject_pattern ç±»å‹çš„å›¾ç‰‡,å¹¶å»ºç«‹åæ ‡åˆ°ç´¢å¼•çš„æ˜ å°„
        from PIL import Image
        img = Image.open(filepath)
        figure_list = ocr_result.get('Data', {}).get('figure', [])
        
        # æ”¶é›†æ‰€æœ‰ subject_pattern ç±»å‹çš„å›¾ç‰‡åŠå…¶åæ ‡
        pattern_map = {}  # åæ ‡ -> ç´¢å¼•
        pattern_index = 1
        
        for fig in figure_list:
            if fig.get('type') == 'subject_pattern':
                points = fig.get('points', [])
                if len(points) >= 4:
                    # è®¡ç®—è¾¹ç•Œæ¡†
                    xs = [p['x'] for p in points]
                    ys = [p['y'] for p in points]
                    x1, y1, x2, y2 = min(xs), min(ys), max(xs), max(ys)
                    
                    # åˆ‡å›¾
                    cropped = img.crop((x1, y1, x2, y2))
                    output_path = images_dir / f"pattern_{pattern_index}.png"
                    cropped.save(output_path)
                    
                    # è®°å½•åæ ‡åˆ°ç´¢å¼•çš„æ˜ å°„ (ä½¿ç”¨ä¸­å¿ƒç‚¹ä½œä¸ºkey)
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    pattern_map[(center_x, center_y)] = pattern_index
                    
                    pattern_index += 1
        
        print(f"ğŸ–¼ï¸  åˆ‡å›¾å®Œæˆ: {pattern_index - 1} å¼ é…å›¾")
        
        # è§£æç»“æœ
        parsed_result = aliyun_ocr.parse_questions(ocr_result)
        
        # ä¸ºæ¯é“é¢˜åŒ¹é…å›¾ç‰‡ç´¢å¼• (ä»åŸå§‹ JSON ä¸­è·å– figure_list)
        data_obj = ocr_result.get('Data', {})
        part_info = data_obj.get('part_info', [])
        
        for part_idx, part_data in enumerate(part_info):
            if part_idx >= len(parsed_result.get('parts', [])):
                continue
                
            parsed_part = parsed_result['parts'][part_idx]
            subject_list = part_data.get('subject_list', [])
            
            for subj_idx, subject_data in enumerate(subject_list):
                if subj_idx >= len(parsed_part.get('questions', [])):
                    continue
                    
                q = parsed_part['questions'][subj_idx]
                q['figures'] = []
                
                # è·å–è¯¥é¢˜ç›®çš„ figure_list
                fig_list = subject_data.get('figure_list', [])
                
                for fig_coords in fig_list:
                    if isinstance(fig_coords, list) and len(fig_coords) >= 4:
                        # è®¡ç®—å›¾ç‰‡ä¸­å¿ƒç‚¹
                        xs = [p['x'] for p in fig_coords]
                        ys = [p['y'] for p in fig_coords]
                        center_x = sum(xs) / len(xs)
                        center_y = sum(ys) / len(ys)
                        
                        # åœ¨ pattern_map ä¸­æŸ¥æ‰¾æœ€æ¥è¿‘çš„å›¾ç‰‡
                        min_dist = float('inf')
                        best_index = None
                        
                        for (px, py), idx in pattern_map.items():
                            dist = ((center_x - px) ** 2 + (center_y - py) ** 2) ** 0.5
                            if dist < min_dist:
                                min_dist = dist
                                best_index = idx
                        
                        if best_index and min_dist < 100:  # è·ç¦»é˜ˆå€¼
                            # åŒæ—¶å­˜ index å’Œ bboxï¼Œä¾›å‰ç«¯è”åˆé«˜äº®ç”¨
                            q['figures'].append({
                                'index': best_index,
                                'bbox': {
                                    'x': min(xs), 'y': min(ys),
                                    'width': max(xs) - min(xs),
                                    'height': max(ys) - min(ys),
                                }
                            })
        
        print(f"âœ“ å›¾ç‰‡åŒ¹é…å®Œæˆ")
        
        # è½¬æ¢ä¸º Markdown (ä¼ å…¥å›¾ç‰‡ç›®å½•ä¿¡æ¯)
        markdown = convert_to_markdown(
            parsed_result, 
            image_output_dir=images_dir,
            original_filename=original_filename
        )
        
        print("âœ“ é˜¿é‡Œäº‘è¯†åˆ«å®Œæˆ")
        
        # æå–åŸå›¾å°ºå¯¸ï¼ˆä¾›å‰ç«¯åæ ‡æ¢ç®—ï¼‰
        data_obj_for_size = ocr_result.get('Data', {})
        image_size = {
            'width': data_obj_for_size.get('width', 0),
            'height': data_obj_for_size.get('height', 0),
        }
        
        return jsonify({
            'status': 'success',
            'image_path': str(filepath),
            'image_filename': file.filename,
            'original_filename': original_filename,
            'image_output_dir': str(images_dir),
            'aliyun_result': parsed_result,
            'raw_ocr_result': ocr_result,
            'image_size': image_size,
            'markdown': markdown,
            'json': parsed_result
        })
    
    except Exception as e:
        print(f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/optimize', methods=['POST'])
def optimize_with_glm():
    """ä½¿ç”¨ GLM ä¼˜åŒ–ç»“æœ"""
    if not glm_optimizer:
        return jsonify({
            'status': 'error',
            'message': 'GLM ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡'
        }), 500
    
    try:
        data = request.json
        image_path = data.get('image_path')
        aliyun_result = data['aliyun_result']
        original_filename = data.get('original_filename', 'result')
        
        print(f"ğŸ¤– å¼€å§‹ GLM ä¼˜åŒ–...")
        
        # è°ƒç”¨ GLM ä¼˜åŒ–
        glm_result = glm_optimizer.optimize(
            aliyun_result=aliyun_result,
            image_url=image_path
        )
        
        # ä¿å­˜ GLM ä¼˜åŒ–ç»“æœ JSON åˆ°å›¾ç‰‡ç›®å½•
        image_output_dir = OUTPUT_FOLDER / original_filename
        glm_json_path = image_output_dir / f"{original_filename}_glm.json"
        with open(glm_json_path, 'w', encoding='utf-8') as f:
            json.dump(glm_result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ GLM ç»“æœå·²ä¿å­˜: {glm_json_path}")
        
        # è½¬æ¢ä¸º Markdownï¼ˆç°åœ¨ glm_result æ‹¥æœ‰å’Œé˜¿é‡Œäº‘åŸå§‹ä¸€è‡´çš„æ•´ä½“ç»“æ„ï¼Œåªæ˜¯æ›´æ–°äº†ç›¸å…³å±æ€§ï¼‰
        glm_markdown = convert_to_markdown(
            glm_result, 
            image_output_dir=image_output_dir, 
            original_filename=original_filename
        )

        print("âœ“ GLM ä¼˜åŒ–å®Œæˆ")
        
        return jsonify({
            'status': 'success',
            'glm_result': glm_result,
            'markdown': glm_markdown,
            'json': glm_result
        })
    
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/optimize_single', methods=['POST'])
def optimize_single_question():
    """ä½¿ç”¨ GLM ä¼˜åŒ–å•é“é¢˜"""
    if not glm_optimizer:
        return jsonify({'status': 'error', 'message': 'GLM ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–'}), 500
    
    try:
        data = request.json
        image_path = data.get('image_path')
        question_id = data.get('question_id')
        aliyun_result = data.get('aliyun_result')
        
        # å¯»æ‰¾å¯¹åº”çš„ question
        target_q = None
        for part in aliyun_result.get('parts', []):
            for q in part.get('questions', []):
                if q.get('id') == question_id:
                    target_q = q
                    break
            if target_q:
                break
                
        if not target_q:
            return jsonify({'status': 'error', 'message': 'æ‰¾ä¸åˆ°å¯¹åº”çš„é¢˜ç›®æ•°æ®'}), 404
            
        print(f"ğŸ¤– å¼€å§‹å•é¢˜ GLM ä¼˜åŒ–: {question_id}")
        
        img_b64 = None
        if image_path and os.path.exists(image_path) and target_q.get('position'):
            # ä½¿ç”¨ PIL æ ¹æ® position è£åˆ‡æŒ‡å®šé¢˜ç›®çš„å›¾ç‰‡åŒºåŸŸ
            try:
                img = Image.open(image_path)
                pos = target_q['position']
                # box: (left, upper, right, lower)
                box = (pos['x'] - 10, pos['y'] - 10, pos['x'] + pos['width'] + 10, pos['y'] + pos['height'] + 10)
                box = (max(0, box[0]), max(0, box[1]), min(img.width, box[2]), min(img.height, box[3]))
                cropped = img.crop(box)
                
                buffer = io.BytesIO()
                # ç»Ÿä¸€è½¬ä¸º RGB ä¿å­˜ JPEG ä»¥ä¼˜åŒ–ä½“ç§¯ï¼Œæˆ–ä¿æŒ PNG
                if cropped.mode != 'RGB':
                    cropped = cropped.convert('RGB')
                cropped.save(buffer, format="JPEG")
                img_b64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            except Exception as e:
                print(f"âš ï¸ å›¾åƒè£åˆ‡å¤±è´¥ï¼Œå°†ä»¥çº¯æ–‡æœ¬æ¨¡å¼ä¼˜åŒ–æœ¬é¢˜: {e}")
        
        # å•é¢˜ä¼˜åŒ–
        optimized_json = glm_optimizer.optimize_single(target_q, image_b64=img_b64)
        # æŠŠä¼˜åŒ–ç»“æœåˆå¹¶è¿› target_qï¼Œè¿™æ ·æ¸²æŸ“æ—¶èƒ½æ‹¿åˆ°æœ€æ–°çš„ text/options
        if optimized_json and not optimized_json.get('error'):
            target_q['glm_optimized'] = optimized_json
            if optimized_json.get('prompt'):
                target_q['type_name'] = optimized_json['prompt']
            target_q['text'] = (optimized_json.get('content') or target_q.get('text', ''))
            if optimized_json.get('opts'):
                target_q['options'] = [
                    {"option": o.get("id", ""), "text": o.get("txt", "")}
                    for o in optimized_json.get('opts', [])
                ]
        
        # æ¸²æŸ“å•é¢˜ HTML ç‰‡æ®µ
        image_output_dir = OUTPUT_FOLDER / data.get('original_filename', 'result')
        markdown_snippet = render_single_question_html(
            target_q,
            image_output_dir=image_output_dir,
            original_filename=data.get('original_filename', 'result'),
            is_optimized=True
        )

        
        return jsonify({
            'status': 'success',
            'question_id': question_id,
            'markdown_snippet': markdown_snippet,
            'optimized_json': optimized_json
        })
        
    except Exception as e:
        print(f"âŒ å•é¢˜ä¼˜åŒ–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'status': 'error', 'message': str(e)}), 500


def render_single_question_html(q: dict, image_output_dir=None, original_filename=None, is_optimized=False):
    """æå–çš„é€šç”¨å•é¢˜ HTML æ¸²æŸ“é€»è¾‘ç‰‡æ®µ"""
    lines = []
    q_id = q.get('id', '')
    
    css_class = 'question-item optim-highlight' if is_optimized else 'question-item'
    lines.append(f'<div class="{css_class}" data-question-id="{q_id}">')
    
    lines.append(f'<div class="q-actions"><button class="btn-optimize-single" onclick="optimizeSingleQuestion(\'{q_id}\')">âœ¨ é‡æ–°ä¼˜åŒ–</button></div>')
    
    type_name = q.get('type_name')
    if type_name:
        lines.append(f"[{type_name}] {q.get('text', '')}\n")
    else:
        lines.append(f"{q.get('text', '')}\n")
    
    figures = q.get('figures', [])
    if figures and image_output_dir and original_filename:
        lines.append('<div class="question-figures">')
        for fig_info in figures:
            fig_index = fig_info.get('index', 0)
            img_url = f"/output/{original_filename}/images/pattern_{fig_index}.png"
            lines.append(f'<img src="{img_url}" alt="é…å›¾{fig_index}" class="question-image" />')
        lines.append('</div>\n')
    
    if q.get('options'):
        lines.append('<div class="options">')
        for opt in q['options']:
            lines.append(f"{opt.get('option', '')}. {opt.get('text', '')}")
        lines.append('</div>\n')

    # å¤„ç†å•é¢˜ä¿®å¤ä¸­é™„å¸¦çš„å­é¢˜ç»“æ„
    glm_opt = q.get('glm_optimized', {})
    if glm_opt.get('subqs'):
        lines.append('<div class="subquestions">')
        for subq in glm_opt['subqs']:
            lines.append(f"  ({subq.get('no', '')}) {subq.get('content', '')}")
        lines.append('</div>\n')
        
    lines.append('</div>\n')
    
    result = "\n".join(lines)
    result = re.sub(r'\$\$(.+?)\$\$', r'$\1$', result)
    return result

@app.route('/output/<path:filepath>')
def serve_output(filepath):
    """è¿”å› output ç›®å½•ä¸­çš„æ–‡ä»¶"""
    return send_from_directory(OUTPUT_FOLDER, filepath)



def convert_to_markdown(parsed_result, image_output_dir=None, original_filename=None):
    """å°†é˜¿é‡Œäº‘ç»“æœè½¬ä¸º Markdown"""
    lines = []
    
    question_number = 1  # å…¨å±€é¢˜å·è®¡æ•°å™¨
    
    for part in parsed_result.get('parts', []):
        if part['title']:  # åªæœ‰éç©ºæ ‡é¢˜æ‰æ˜¾ç¤º
            lines.append(f"## {part['title']}\n")
        
        for q in part.get('questions', []):
            snippet = render_single_question_html(
                q, 
                image_output_dir=image_output_dir, 
                original_filename=original_filename
            )
            lines.append(snippet)
            question_number += 1  # é€’å¢é¢˜å·
    
    result = "\n".join(lines)
    return result


def convert_glm_to_markdown(glm_result):
    """å°† GLM ç»“æœè½¬ä¸º Markdown"""
    lines = []
    
    for section in glm_result.get('sections', []):
        lines.append(f"## {section.get('no', '')}ã€{section.get('title', '')}\n")
        
        if section.get('desc'):
            lines.append(f"*{section['desc']}*\n")
        
        for q in section.get('qs', []):
            # æ·»åŠ é¢˜ç›® ID (ç”¨äºå‰ç«¯è”åŠ¨)
            q_no = q.get('no', '')
            lines.append(f'<div class="question-item" data-question-id="{q_no}">')
            
            prompt = q.get('prompt', '')
            content = q.get('content', '')
            
            # é¢˜å¹²
            if prompt:
                lines.append(f"[{prompt}] {content}\n")
            else:
                lines.append(f"{content}\n")
            
            # é€‰é¡¹ (å•ç‹¬æ˜¾ç¤º)
            if q.get('opts'):
                lines.append('<div class="options">')
                for opt in q['opts']:
                    lines.append(f"{opt['id']}. {opt['txt']}")
                lines.append('</div>\n')
            
            # å­é¢˜
            if q.get('subqs'):
                lines.append('<div class="subquestions">')
                for subq in q['subqs']:
                    lines.append(f"  ({subq.get('no', '')}) {subq.get('content', '')}")
                lines.append('</div>\n')
            
            lines.append('</div>\n')
    
    return "\n".join(lines)


if __name__ == '__main__':
    print("=" * 60)
    print("è¯•å·è¯†åˆ« Demo - åç«¯æœåŠ¡")
    print("=" * 60)
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    init_processors()
    
    print("\nğŸš€ æœåŠ¡å¯åŠ¨ä¸­...")
    print("   è®¿é—®åœ°å€: http://localhost:8000")
    print("=" * 60)
    
    app.run(debug=True, host='0.0.0.0', port=8000)
